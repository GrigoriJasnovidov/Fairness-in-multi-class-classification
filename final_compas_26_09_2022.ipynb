{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6f0336a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#general imports \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVC \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import random\n",
    "from lightgbm import LGBMClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# imports for FMCLP algorithm\n",
    "from final_fmclp_26_09_2022 import cuae, fmclp, synthetic_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73f78ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing one of compas datasets\n",
    "\n",
    "d = pd.read_csv('compas-scores-raw.csv')\n",
    "                \n",
    "del d['Person_ID']\n",
    "del d['AssessmentID']\n",
    "del d['Case_ID']\n",
    "del d['LastName']\n",
    "del d['MiddleName']\n",
    "del d['FirstName']\n",
    "del d['RawScore']\n",
    "del d['DecileScore']\n",
    "del d['IsCompleted']\n",
    "del d['IsDeleted']\n",
    "del d['AssessmentReason']\n",
    "del d['RecSupervisionLevelText']\n",
    "del d['DisplayText']\n",
    "\n",
    "del d['Screening_Date']\n",
    "del d['DateOfBirth']\n",
    "\n",
    "def race(x):\n",
    "    if x == 'African-American':\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "d['attr']= d['Ethnic_Code_Text'].apply(race)\n",
    "del d['Ethnic_Code_Text']\n",
    "\n",
    "def targeter(x):\n",
    "    if x == 'Low':\n",
    "        return 0\n",
    "    elif x =='Medium':\n",
    "        return 1\n",
    "    else:\n",
    "        return 2\n",
    "d['target'] = d['ScoreText'].apply(targeter)\n",
    "del d['ScoreText']\n",
    "d = pd.get_dummies(d, drop_first = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d72e7a29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8314249712376047"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fit LGBM classifier\n",
    "y = d.drop('target',axis=1)\n",
    "x = d['target']\n",
    "    \n",
    "y_train,y_test,x_train,x_test = train_test_split(y,x,test_size = 0.3)\n",
    "\n",
    "estimator = LGBMClassifier()\n",
    "estimator.fit(y_train,x_train)\n",
    "estimator_pred= estimator.predict(y_test)\n",
    "accuracy_score(estimator_pred,x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03526837",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "CPU times: user 2h 51min 6s, sys: 41min 29s, total: 3h 32min 35s\n",
      "Wall time: 2h 9min 59s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#experiment\n",
    "fair_diff = []\n",
    "fair_ratio = []\n",
    "fair_variation = []\n",
    "fair_accuracy = []\n",
    "unfair_diff = []\n",
    "unfair_ratio = []\n",
    "unfair_variation = []\n",
    "unfair_accuracy = []\n",
    "\n",
    "results = []\n",
    "for i in range(100):\n",
    "    main_state = random.choice(range(1000))\n",
    "    res = fmclp(dataset = d, estimator = estimator, number_iterations = 20, prefit = False, \n",
    "                    interior_classifier = 'knn', random_state = main_state,\n",
    "            verbose = False, multiplier =35)\n",
    "    results.append(res)\n",
    "    unfair_diff.append(res['fairness_of_initial_classifier']['diff'])\n",
    "    unfair_ratio.append(res['fairness_of_initial_classifier']['ratio'])\n",
    "    unfair_variation.append(res['fairness_of_initial_classifier']['variation'])\n",
    "    unfair_accuracy.append(res['accuracy_of_initial_classifier'])\n",
    "    \n",
    "    fair_diff.append(res['fairness_of_fair_classifier']['diff'])\n",
    "    fair_ratio.append(res['fairness_of_fair_classifier']['ratio'])\n",
    "    fair_variation.append(res['fairness_of_fair_classifier']['variation'])\n",
    "    fair_accuracy.append(res['accuracy_of_fair_classifier'])\n",
    "    \n",
    "    name = f\"compas_trials/trial_№{i+1}.txt\"\n",
    "    file = open(name,'w')\n",
    "    file.write(f\"\"\"unfair_total_diff: {res['fairness_of_initial_classifier']['diff']}\n",
    "unfair_ratio: {res['fairness_of_initial_classifier']['ratio']}\n",
    "unfair_variation: {res['fairness_of_initial_classifier']['variation']}\n",
    "unfair_accuracy: {res['accuracy_of_initial_classifier']}\n",
    "fair_diff: {res['fairness_of_fair_classifier']['diff']}\n",
    "fair_ratio: {res['fairness_of_fair_classifier']['ratio']}\n",
    "fair_variation: {res['fairness_of_fair_classifier']['variation']}\n",
    "fair_accuracy: {res['accuracy_of_fair_classifier']}\n",
    "interior_classifier: knn\n",
    "multiplier: 35\n",
    "main_state: {main_state}\n",
    "    \"\"\")\n",
    "    file.close()\n",
    "    res['fairness_of_fair_classifier']['df'].to_csv(f\"compas_trials/compas_trial_№{i+1} cuae-metric-fair.csv\")\n",
    "    res['fairness_of_initial_classifier']['df'].to_csv(f\"compas_trials/compas_trial_№{i+1} cuae-metric-unfair.csv\")\n",
    "    print(i+1)\n",
    "    \n",
    "fair_diff = np.array(fair_diff)\n",
    "fair_ratio = np.array(fair_ratio)\n",
    "fair_variation = np.array(fair_variation)\n",
    "fair_accuracy = np.array(fair_accuracy)\n",
    "unfair_diff = np.array(unfair_diff)\n",
    "unfair_ratio = np.array(unfair_ratio)\n",
    "unfair_variation = np.array(unfair_variation)\n",
    "unfair_accuracy = np.array(unfair_accuracy)\n",
    "\n",
    "file = open('compas_trials/compas_trials.txt','w')\n",
    "file.write(\n",
    "f\"\"\"dataset for initial classifier training: 200 \n",
    "classifier: LGBMClassifier()\n",
    "number_iterations: 10\n",
    "multiplier:25\n",
    "interior_classifier: knn\n",
    "fair_diff: {fair_diff}\n",
    "fair_ratio: {fair_ratio}\n",
    "fair_variation: {fair_variation}\n",
    "fair_accuracy: {fair_accuracy}\n",
    "unfair_diff: {unfair_diff}\n",
    "unfair_ratio: {unfair_ratio}\n",
    "unfair_variation: {unfair_variation}\n",
    "unfair_accuracy: {unfair_accuracy}\"\"\")\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa054e10-1971-4234-8db7-96f94ba73abf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.15045373668539327, 0.1467769521024428)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fair_diff.mean(),unfair_diff.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0cefe1c5-cd6f-44eb-a33e-88a8febaa4c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.3323821901573902, 1.3537608015695406)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fair_ratio.mean(),unfair_ratio.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98e4509c-8b99-407d-9413-3ed4113c14be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5048978810015841, 0.5701714157738056)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fair_variation.mean(),unfair_variation.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "32e733d9-e4a2-4200-bdb7-e4d8b5bb9e17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8262152389717967, 0.8327006771415424)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fair_accuracy.mean(), unfair_accuracy.mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
